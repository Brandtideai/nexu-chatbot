<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
<title>Nexus – BrandTide AI Chat</title>
<style>
  :root {
    --brand-teal: #26a69a;
    --bg-dark: #0f0f0f;
    --font: 'Segoe UI', sans-serif;
    --shadow: 0 0 16px rgba(38, 166, 154, 0.6);
  }
  body {
    margin: 0;
    background: var(--bg-dark);
    font-family: var(--font);
    color: white;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
  }
  #nexus-panel {
    display: flex;
    position: fixed;
    bottom: 80px;
    right: 10px;
    width: 85vw;
    max-width: 320px;
    height: 80vh;
    max-height: 500px;
    border-radius: 20px;
    box-shadow: var(--shadow);
    z-index: 9999;
    flex-direction: column;
    overflow: hidden;
    font-family: var(--font);
    background: url('https://brandtideai.com/wp-content/uploads/2025/05/ChatGPT-Image-May-16-2025-01_49_41-AM-2.png') no-repeat center;
    background-size: cover;
    background-color: #303030;
    border: 2px solid var(--brand-teal);
  }
  #nexus-close {
    position: absolute;
    top: 10px;
    right: 10px;
    background: transparent;
    border: none;
    cursor: pointer;
    z-index: 10000;
  }
  #nexus-close svg {
    width: 24px;
    height: 24px;
    fill: var(--brand-teal);
  }
  #nexus-avatar {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: url('https://brandtideai.com/wp-content/uploads/2025/05/ChatGPT-Image-May-16-2025-01_50_12-AM.png') no-repeat center;
    background-size: cover;
    margin: 10px auto 3px;
    box-shadow: 0 0 8px rgba(38, 166, 154, 0.4);
    flex-shrink: 0;
  }
  #nexus-header {
    text-align: center;
    color: white;
    font-weight: 600;
    font-size: 13px;
    padding: 0 10px 6px;
    flex-shrink: 0;
  }
  #nexus-body {
    flex: 1;
    padding: 8px;
    overflow-y: auto;
    background: transparent;
    font-size: 13px;
    display: flex;
    flex-direction: column;
    gap: 10px;
  }
  .msg {
    max-width: 75%;
    padding: 8px 12px;
    border-radius: 20px;
    position: relative;
    word-wrap: break-word;
    display: flex;
    align-items: center;
    gap: 5px;
  }
  .user {
    align-self: flex-end;
    color: #e0e0e0;
    background: #1a3c34;
  }
  .bot {
    align-self: flex-start;
    color: #b0b0b0;
    background: #2b2b2b;
  }
  .speak-btn {
    background: var(--brand-teal);
    border: none;
    border-radius: 50%;
    width: 20px;
    height: 20px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  .speak-btn svg {
    width: 12px;
    height: 12px;
    fill: white;
  }
  .thinking {
    align-self: flex-start;
    display: flex;
    align-items: center;
    gap: 5px;
    padding: 8px 12px;
    border-radius: 20px;
    background: #2b2b2b;
  }
  .thinking .dot {
    width: 6px;
    height: 6px;
    background: var(--brand-teal);
    border-radius: 50%;
    animation: dots 1.5s infinite;
  }
  .thinking .dot:nth-child(2) { animation-delay: 0.2s; }
  .thinking .dot:nth-child(3) { animation-delay: 0.4s; }
  @keyframes dots {
    0%, 20% { transform: translateY(0); }
    40% { transform: translateY(-5px); }
    60% { transform: translateY(0); }
  }
  #nexus-footer {
    display: flex;
    align-items: center;
    padding: 8px;
    background: #191919;
    border-top: 1px solid #333;
    gap: 6px;
    flex-shrink: 0;
  }
  #nexus-input {
    flex: 1;
    border: none;
    border-radius: 999px;
    padding: 6px 10px;
    background: #2b2b2b;
    color: white;
    font-size: 13px;
    outline: none;
  }
  #nexus-send {
    background: var(--brand-teal);
    border: none;
    padding: 6px 10px;
    border-radius: 999px;
    color: white;
    font-weight: bold;
    cursor: pointer;
    font-size: 12px;
    box-shadow: var(--shadow);
  }
  #nexus-mic {
    cursor: pointer;
    position: relative;
  }
  #nexus-mic svg {
    width: 18px;
    height: 18px;
    fill: var(--brand-teal);
  }
  #nexus-mic.active svg {
    fill: #ff5555;
    animation: pulse 1.5s infinite;
  }
  #speak-test {
    position: absolute;
    top: 40px;
    right: 10px;
    background: var(--brand-teal);
    border: none;
    padding: 5px 10px;
    border-radius: 5px;
    color: white;
    cursor: pointer;
    font-size: 12px;
    z-index: 10000;
  }
  @keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.2); }
  }
  @media (max-width: 767px) {
    #nexus-panel {
      top: 0;
      left: 0;
      bottom: auto;
      right: auto;
      width: 100vw;
      height: 100vh;
      max-width: none;
      max-height: none;
      border-radius: 0;
      border: none;
      box-shadow: none;
    }
    #nexus-close {
      top: 15px;
      right: 15px;
    }
    #nexus-close svg {
      width: 30px;
      height: 30px;
    }
    #speak-test {
      top: 50px;
      right: 15px;
      font-size: 14px;
    }
    #nexus-avatar {
      width: 70px;
      height: 70px;
      margin: 15px auto 5px;
    }
    #nexus-header {
      font-size: 18px;
      padding: 0 15px 8px;
    }
    #nexus-body {
      padding: 10px;
      font-size: 18px;
    }
    .msg {
      padding: 10px 14px;
      border-radius: 25px;
    }
    .thinking {
      padding: 10px 14px;
      border-radius: 25px;
    }
    .thinking .dot {
      width: 8px;
      height: 8px;
    }
    #nexus-footer {
      padding: 10px;
      gap: 8px;
    }
    #nexus-input {
      padding: 8px 12px;
      font-size: 18px;
    }
    #nexus-send {
      padding: 8px 12px;
      font-size: 16px;
    }
    #nexus-mic svg {
      width: 24px;
      height: 24px;
    }
  }
  @media (min-width: 768px) and (max-width: 1024px) {
    #nexus-panel {
      width: 70vw;
      max-width: 400px;
      max-height: 600px;
    }
  }
  @media (min-width: 1025px) {
    #nexus-panel {
      width: 340px;
      max-height: 520px;
    }
  }
</style>
</head>
<body>
  <div id="nexus-panel">
    <button id="nexus-close" onclick="closeChatWindow()">
      <svg viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
    </button>
    <button id="speak-test" onclick="speakTest()">Speak Test</button>
    <div id="nexus-avatar"></div>
    <div id="nexus-header">Nexus – BrandTide AI</div>
    <div id="nexus-body">
      <div class="msg bot">Hi! How can I assist you today?</div>
    </div>
    <div id="nexus-footer">
      <div id="nexus-mic" title="Start/stop voice input">
        <svg id="mic-icon" viewBox="0 0 24 24"><path d="M12 1a3 3 0 0 1 3 3v7a3 3 0 0 1-6 0V4a3 3 0 0 1 3-3zm5 10a5 5 0 0 1-10 0H5a7 7 0 0 0 14 0h-2zm-5 11a1 1 0 0 1-1-1v-2h2v2a1 1 0 0 1-1 1z"/></svg>
      </div>
      <input id="nexus-input" placeholder="Ask Nexus anything..." autocomplete="off" />
      <button id="nexus-send">Send</button>
    </div>
  </div>
  <script>
    const input = document.getElementById("nexus-input");
    const sendBtn = document.getElementById("nexus-send");
    const body = document.getElementById("nexus-body");
    const micIcon = document.getElementById("nexus-mic");
    let isMicActive = false;
    let recognition = null;
    let voicesLoaded = false;
    let lastSpeechTime = 0;
    const DEBOUNCE_DELAY = 1000;
    let messageCounter = 0;
    let audioContext = null;
    let micErrorCount = 0;
    const MAX_MIC_ERRORS = 3;

    function appendMsg(content, cls) {
      const div = document.createElement('div');
      div.className = `msg ${cls}`;
      if (cls === 'bot') {
        messageCounter++;
        div.innerHTML = `
          <span>${content}</span>
          <button class="speak-btn">
            <svg viewBox="0 0 24 24"><path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/></svg>
          </button>`;
        div.dataset.messageId = messageCounter;
        div.dataset.messageContent = content;
        const speakButton = div.querySelector('.speak-btn');
        speakButton.addEventListener('click', () => {
          console.log('Trying to speak message:', messageCounter);
          speakMessage(messageCounter);
        });
      } else {
        div.innerHTML = content;
      }
      body.appendChild(div);
      div.scrollIntoView({ behavior: "smooth" });
    }

    function showThinkingAnimation() {
      const thinkingDiv = document.createElement('div');
      thinkingDiv.className = 'thinking';
      thinkingDiv.innerHTML = '<span class="dot"></span><span class="dot"></span><span class="dot"></span>';
      thinkingDiv.id = 'thinking-indicator';
      body.appendChild(thinkingDiv);
      thinkingDiv.scrollIntoView({ behavior: "smooth" });
    }

    function removeThinkingAnimation() {
      const thinkingDiv = document.getElementById("thinking-indicator");
      if (thinkingDiv) {
        thinkingDiv.remove();
      }
    }

    function closeChatWindow() {
      try {
        window.parent.postMessage('closeChat', '*');
        console.log('Close message sent at', new Date().toISOString());
      } catch (err) {
        console.error('Failed to close chat window:', err);
        appendMsg("Error closing chat window. Please try refreshing the page.", "bot");
      }
    }

    // Initialize AudioContext for audio permission prompt
    function initAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        console.log('AudioContext initialized');
      }
      if (audioContext.state === 'suspended') {
        audioContext.resume().then(() => {
          console.log('AudioContext resumed');
        }).catch(err => {
          console.error('Failed to resume AudioContext:', err);
          appendMsg("Audio permission error: Please allow audio playback in browser settings (e.g., chrome://settings/content/sound).", "bot");
        });
      }
    }

    // Play a test beep to confirm audio output
    function playTestBeep() {
      if (!audioContext) initAudioContext();
      const oscillator = audioContext.createOscillator();
      oscillator.type = 'sine';
      oscillator.frequency.setValueAtTime(440, audioContext.currentTime); // A4 note
      oscillator.connect(audioContext.destination);
      oscillator.start();
      oscillator.stop(audioContext.currentTime + 0.5);
      console.log('Test beep played');
    }

    // Unlock audio on user interaction
    window.addEventListener("click", () => {
      if (audioContext && audioContext.state === "suspended") {
        audioContext.resume().then(() => {
          console.log("Audio resumed after user click");
        });
      }
      if (speechSynthesis.paused) {
        speechSynthesis.resume();
        console.log("Speech synthesis resumed after user click");
      }
    }, { once: true });

    function getFemaleBritishVoice() {
      const voices = speechSynthesis.getVoices();
      console.log('Available voices:', voices.map(v => `${v.name} (${v.lang})`));
      const femaleBritishVoice = voices.find(voice => 
        voice.lang === 'en-GB' && 
        (voice.name.includes('Female') || 
         voice.name.includes('Samantha') || 
         voice.name.includes('Kate') || 
         voice.name.includes('Serena')) && 
        !voice.name.includes('Male') && 
        !voice.name.includes('Daniel')
      ) || voices.find(voice => voice.lang === 'en-GB') || voices[0];
      if (femaleBritishVoice) {
        console.log('Selected voice:', femaleBritishVoice.name, femaleBritishVoice.lang);
      } else {
        console.warn('No suitable voice found, using first available voice');
      }
      return femaleBritishVoice;
    }

    // Ensure voices are loaded
    speechSynthesis.onvoiceschanged = () => {
      voicesLoaded = true;
      console.log('Voices loaded:', speechSynthesis.getVoices().map(v => `${v.name} (${v.lang})`));
    };

    // Force voice load on page load
    window.addEventListener('load', () => {
      initAudioContext();
      speechSynthesis.getVoices();
      setTimeout(() => {
        if (!voicesLoaded) {
          speechSynthesis.getVoices();
          console.log('Forced voice load after 200ms');
        }
      }, 200);
    });

    // Test SpeechSynthesis support
    if ('speechSynthesis' in window) {
      console.log('SpeechSynthesis supported by browser');
    } else {
      console.error('SpeechSynthesis not supported by browser');
      appendMsg("Speech output is not supported by your browser. Please try a different browser like Chrome or Firefox.", "bot");
    }

    function speakTest() {
      const testUtterance = new SpeechSynthesisUtterance("Testing speech synthesis.");
      testUtterance.voice = null; // Use default system voice
      testUtterance.lang = "en-GB";
      testUtterance.rate = 0.9;
      speechSynthesis.cancel(); // Clear queue
      speechSynthesis.speak(testUtterance);
      console.log('Speak test initiated');
    }

    function speakMessage(messageId) {
      console.log('speakMessage called with messageId:', messageId);
      initAudioContext();
      playTestBeep();

      const msgEl = document.querySelector(`.msg[data-message-id="${messageId}"]`);
      if (!msgEl) {
        console.error("Couldn't find message with ID", messageId);
        appendMsg("Error: Could not find message to speak.", "bot");
        return;
      }

      const text = msgEl.dataset.messageContent?.trim();
      if (!text || text.length < 2) {
        console.warn("No message content found or too short to speak:", text);
        appendMsg("Error: Message content is empty or too short to speak.", "bot");
        return;
      }

      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-GB';
      utter.rate = 0.9;

      const voice = getFemaleBritishVoice();
      if (voice) utter.voice = voice;

      speechSynthesis.cancel();
      speechSynthesis.speak(utter);
      console.log('Speech synthesis initiated for message:', text);
    }

    async function send() {
      console.log('send() called');
      const text = input.value.trim();
      if (!text) {
        console.log('No text entered, exiting send()');
        return;
      }
      appendMsg(text, 'user');
      input.value = '';
      showThinkingAnimation();
      console.log('Starting wait timer at', new Date().toISOString());
      try {
        setTimeout(async () => {
          console.log('Wait timer ended at', new Date().toISOString());
          try {
            const res = await fetch("https://aichatbot-vx48.vercel.app/api/chat", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ messages: [{ role: "user", content: text }] })
            });
            const data = await res.json();
            removeThinkingAnimation();
            const reply = data.reply || "No response";
            appendMsg(reply, "bot");
          } catch (err) {
            console.error('Fetch error in send():', err);
            removeThinkingAnimation();
            appendMsg("Connection error. Ensure you're on HTTPS and check your network.", "bot");
          }
        }, 2000); // 2-second delay
      } catch (err) {
        console.error('Error in send() setTimeout:', err);
        removeThinkingAnimation();
        appendMsg("Error sending message: " + err.message, "bot");
      }
    }

    // Add event listeners for send button and keypress
    try {
      sendBtn.addEventListener('click', () => {
        console.log('Send button clicked');
        send();
      });
    } catch (err) {
      console.error('Error attaching click listener to sendBtn:', err);
      appendMsg("Error initializing send button: " + err.message, "bot");
    }

    try {
      input.addEventListener("keypress", e => {
        if (e.key === "Enter") {
          console.log('Enter key pressed');
          send();
        }
      });
    } catch (err) {
      console.error('Error attaching keypress listener to input:', err);
      appendMsg("Error initializing input keypress: " + err.message, "bot");
    }

    micIcon.onclick = async () => {
      console.log('micIcon clicked');
      if (micErrorCount >= MAX_MIC_ERRORS) {
        appendMsg("Voice input disabled due to repeated errors. Please type your message instead.", "bot");
        micIcon.style.display = 'none';
        return;
      }
      if (!window.location.protocol.startsWith('https')) {
        appendMsg("Voice input requires HTTPS. Please access this site via a secure connection.", "bot");
        appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
        return;
      }

      if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {
        appendMsg("Voice input is not supported on this device.", "bot");
        return;
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

      if (micIcon.classList.contains('active')) {
        if (recognition) {
          recognition.stop();
          recognition = null;
          micIcon.classList.remove('active');
          isMicActive = false;
          console.log('Microphone stopped');
        }
        return;
      }

      recognition = new SpeechRecognition();
      recognition.lang = "en-GB";
      recognition.interimResults = true;
      recognition.maxAlternatives = 1;
      recognition.continuous = false;

      try {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
        console.log('Microphone permission status:', permissionStatus.state);
        if (permissionStatus.state === 'denied') {
          appendMsg("Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone.", "bot");
          appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
          return;
        }

        await navigator.mediaDevices.getUserMedia({ audio: true });
        recognition.start();
        micIcon.classList.add('active');
        isMicActive = true;
        console.log('Microphone started successfully');
      } catch (err) {
        console.error('Microphone initialization error:', err);
        appendMsg("Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone. Error: " + err.message, "bot");
        appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
        return;
      }

      recognition.onresult = (e) => {
        const now = Date.now();
        if (now - lastSpeechTime < DEBOUNCE_DELAY) {
          console.log('Debounced duplicate speech input');
          return;
        }
        lastSpeechTime = now;
        const transcript = e.results[0][0].transcript;
        console.log('Speech recognition result:', transcript);
        input.value = transcript;
        send();
      };

      recognition.onerror = (e) => {
        micIcon.classList.remove('active');
        isMicActive = false;
        micErrorCount++;
        let errorMsg = "Voice input error: ";
        if (e.error === "no-speech") {
          errorMsg += "No speech detected. Please try again.";
        } else if (e.error === "audio-capture") {
          errorMsg += "No microphone detected. Please ensure a microphone is connected.";
        } else if (e.error === "not-allowed") {
          errorMsg += "Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone.";
        } else if (e.error === "network") {
          errorMsg += "Network error with speech recognition. Please check your internet connection, disable VPN if active, and ensure Google's speech recognition service is accessible.";
        } else {
          errorMsg += e.error;
        }
        console.error('Speech recognition error:', e.error);
        appendMsg(errorMsg, "bot");
        appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
        if (micErrorCount >= MAX_MIC_ERRORS) {
          appendMsg("Voice input disabled due to repeated errors. Please type your message instead.", "bot");
          micIcon.style.display = 'none';
        }
        recognition = null;
      };

      recognition.onend = () => {
        console.log('Speech recognition ended');
        if (micIcon.classList.contains('active') && micErrorCount < MAX_MIC_ERRORS) {
          recognition.start();
          console.log('Speech recognition restarted');
        }
      };
    };
  </script>
</body>
</html>
