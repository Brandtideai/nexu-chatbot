<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
<title>Nexus – BrandTide AI Chat</title>
<style>
  :root {
    --brand-teal: #26a69a;
    --bg-dark: #0f0f0f;
    --font: 'Segoe UI', sans-serif;
    --shadow: 0 0 16px rgba(38, 166, 154, 0.6);
  }
  body {
    margin: 0;
    background: var(--bg-dark);
    font-family: var(--font);
    color: white;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
  }
  #nexus-panel {
    display: flex;
    position: fixed;
    bottom: 80px;
    right: 10px;
    width: 85vw;
    max-width: 320px;
    height: 80vh;
    max-height: 500px;
    border-radius: 20px;
    box-shadow: var(--shadow);
    z-index: 9999;
    flex-direction: column;
    overflow: hidden;
    font-family: var(--font);
    background: url('https://brandtideai.com/wp-content/uploads/2025/05/ChatGPT-Image-May-16-2025-01_49_41-AM-2.png') no-repeat center;
    background-size: cover;
    background-color: #303030;
    border: 2px solid var(--brand-teal);
    padding-bottom: env(safe-area-inset-bottom);
    box-sizing: border-box;
  }
  #nexus-close {
    position: absolute;
    top: 10px;
    right: 10px;
    background: transparent;
    border: none;
    cursor: pointer;
    z-index: 10000;
  }
  #nexus-close svg {
    width: 24px;
    height: 24px;
    fill: var(--brand-teal);
  }
  #nexus-avatar {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: url('https://brandtideai.com/wp-content/uploads/2025/05/ChatGPT-Image-May-16-2025-01_50_12-AM.png') no-repeat center;
    background-size: cover;
    margin: 10px auto 3px;
    box-shadow: 0 0 8px rgba(38, 166, 154, 0.4);
    flex-shrink: 0;
  }
  #nexus-header {
    text-align: center;
    color: white;
    font-weight: 600;
    font-size: 13px;
    padding: 0 10px 6px;
    flex-shrink: 0;
  }
  #nexus-body {
    flex: 1;
    padding: 8px;
    overflow-y: auto;
    background: transparent;
    font-size: 13px;
    display: flex;
    flex-direction: column;
    gap: 10px;
  }
  .msg {
    max-width: 75%;
    padding: 8px 12px;
    border-radius: 20px;
    position: relative;
    word-wrap: break-word;
  }
  .user {
    align-self: flex-end;
    color: #e0e0e0;
    background: #1a3c34;
  }
  .bot {
    align-self: flex-start;
    color: #b0b0b0;
    background: #2b2b2b;
  }
  .bot p {
    margin: 0 0 8px 0; /* Add spacing between paragraphs in bot messages */
    line-height: 1.4; /* Improve readability with line spacing */
  }
  .bot p:last-child {
    margin-bottom: 0; /* Remove margin from the last paragraph */
  }
  .thinking {
    align-self: flex-start;
    display: flex;
    align-items: center;
    gap: 5px;
    padding: 8px 12px;
    border-radius: 20px;
    background: #2b2b2b;
  }
  .thinking .dot {
    width: 6px;
    height: 6px;
    background: var(--brand-teal);
    border-radius: 50%;
    animation: dots 1.5s infinite;
  }
  .thinking .dot:nth-child(2) { animation-delay: 0.2s; }
  .thinking .dot:nth-child(3) { animation-delay: 0.4s; }
  @keyframes dots {
    0%, 20% { transform: translateY(0); }
    40% { transform: translateY(-5px); }
    60% { transform: translateY(0); }
  }
  #nexus-footer {
    display: flex;
    align-items: center;
    padding: 8px;
    padding-bottom: calc(8px + env(safe-area-inset-bottom));
    background: #191919;
    border-top: 1px solid #333;
    gap: 6px;
    flex-shrink: 0;
    position: relative;
    z-index: 10001;
  }
  #nexus-input {
    flex: 1;
    border: none;
    border-radius: 999px;
    padding: 6px 10px;
    background: #2b2b2b;
    color: white;
    font-size: 13px;
    outline: none;
  }
  #nexus-send {
    background: var(--brand-teal);
    border: none;
    padding: 6px 10px;
    border-radius: 999px;
    color: white;
    font-weight: bold;
    cursor: pointer;
    font-size: 12px;
    box-shadow: var(--shadow);
  }
  #nexus-mic {
    cursor: pointer;
    position: relative;
  }
  #nexus-mic svg {
    width: 18px;
    height: 18px;
    fill: var(--brand-teal);
  }
  #nexus-mic.active svg {
    fill: #ff5555;
    animation: pulse 1.5s infinite;
  }
  @keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.2); }
  }
  @media (max-width: 767px) {
    #nexus-panel {
      top: 0;
      left: 0;
      bottom: auto;
      right: auto;
      width: 100vw;
      height: calc(100vh - env(safe-area-inset-bottom));
      max-width: none;
      max-height: none;
      border-radius: 0;
      border: none;
      box-shadow: none;
    }
    #nexus-close {
      top: 15px;
      right: 15px;
    }
    #nexus-close svg {
      width: 30px;
      height: 30px;
    }
    #nexus-avatar {
      width: 70px;
      height: 70px;
      margin: 15px auto 5px;
    }
    #nexus-header {
      font-size: 18px;
      padding: 0 15px 8px;
    }
    #nexus-body {
      padding: 10px;
      font-size: 18px;
    }
    .msg {
      padding: 10px 14px;
      border-radius: 25px;
    }
    .thinking {
      padding: 10px 14px;
      border-radius: 25px;
    }
    .thinking .dot {
      width: 8px;
      height: 8px;
    }
    #nexus-footer {
      padding: 10px;
      padding-bottom: calc(10px + env(safe-area-inset-bottom));
      gap: 8px;
    }
    #nexus-input {
      padding: 8px 12px;
      font-size: 18px;
    }
    #nexus-send {
      padding: 8px 12px;
      font-size: 16px;
    }
    #nexus-mic svg {
      width: 24px;
      height: 24px;
    }
  }
  @media (min-width: 768px) and (max-width: 1024px) {
    #nexus-panel {
      width: 70vw;
      max-width: 400px;
      max-height: 600px;
    }
  }
  @media (min-width: 1025px) {
    #nexus-panel {
      width: 340px;
      max-height: 520px;
    }
  }
</style>
</head>
<body>
  <div id="nexus-panel">
    <button id="nexus-close" onclick="closeChatWindow()">
      <svg viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
    </button>
    <div id="nexus-avatar"></div>
    <div id="nexus-header">Nexus – BrandTide AI</div>
    <div id="nexus-body">
      <div class="msg bot">Hi! How can I assist you today?</div>
    </div>
    <div id="nexus-footer">
      <div id="nexus-mic" title="Start/stop voice input">
        <svg id="mic-icon" viewBox="0 0 24 24"><path d="M12 1a3 3 0 0 1 3 3v7a3 3 0 0 1-6 0V4a3 3 0 0 1 3-3zm5 10a5 5 0 0 1-10 0H5a7 7 0 0 0 14 0h-2zm-5 11a1 1 0 0 1-1-1v-2h2v2a1 1 0 0 1-1 1z"/></svg>
      </div>
      <input id="nexus-input" placeholder="Ask Nexus anything..." autocomplete="off" />
      <button id="nexus-send">Send</button>
    </div>
  </div>
  <script>
    const input = document.getElementById("nexus-input");
    const sendBtn = document.getElementById("nexus-send");
    const body = document.getElementById("nexus-body");
    const micIcon = document.getElementById("nexus-mic");
    let isMicActive = false;
    let recognition = null;
    let voicesLoaded = false;
    let lastSpeechTime = 0;
    let messageCounter = 0;
    let audioContext = null;
    let micErrorCount = 0;
    let isSpeaking = false;
    const MAX_MIC_ERRORS = 3;
    const DEBOUNCE_DELAY = 1000;
    const RECOGNITION_RESTART_DELAY = 1500;

    // Browser and device detection
    const isIOS = /iPhone|iPad|iPod/.test(navigator.userAgent);
    const isChromeIOS = /CriOS/.test(navigator.userAgent) && isIOS;
    const isSafariIOS = /Safari/.test(navigator.userAgent) && !/CriOS/.test(navigator.userAgent) && isIOS;

    // Disable voice features and remove mic icon for iOS users
    if (isIOS) {
      micIcon.style.display = 'none';
    }

    function appendMsg(content, cls) {
      const div = document.createElement('div');
      div.className = `msg ${cls}`;
      if (cls === 'bot') {
        messageCounter++;
        div.innerHTML = content; // Render content as HTML to support paragraph tags
        div.dataset.messageId = messageCounter;
        div.dataset.messageContent = content;
      } else {
        div.innerHTML = content;
      }
      body.appendChild(div);
      div.scrollIntoView({ behavior: "smooth" });
      return messageCounter;
    }

    function showThinkingAnimation() {
      const thinkingDiv = document.createElement('div');
      thinkingDiv.className = 'thinking';
      thinkingDiv.innerHTML = '<span class="dot"></span><span class="dot"></span><span class="dot"></span>';
      thinkingDiv.id = 'thinking-indicator';
      body.appendChild(thinkingDiv);
      thinkingDiv.scrollIntoView({ behavior: "smooth" });
    }

    function removeThinkingAnimation() {
      const thinkingDiv = document.getElementById("thinking-indicator");
      if (thinkingDiv) {
        thinkingDiv.remove();
      }
    }

    function closeChatWindow() {
      try {
        if (!isIOS) {
          speechSynthesis.cancel();
          console.log('Speech synthesis canceled on window close');
          if (recognition && isMicActive) {
            recognition.stop();
            recognition = null;
            isMicActive = false;
            micIcon.classList.remove('active');
            console.log('Speech recognition stopped on window close');
          }
        }
        window.parent.postMessage('closeChat', '*');
        console.log('Close message sent at', new Date().toISOString());
      } catch (err) {
        console.error('Failed to close chat window:', err);
        appendMsg("Error closing chat window. Please try refreshing the page.", "bot");
      }
    }

    function initAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        console.log('AudioContext initialized');
      }
      if (audioContext.state === 'suspended') {
        audioContext.resume().then(() => {
          console.log('AudioContext resumed');
        }).catch(err => {
          console.error('Failed to resume AudioContext:', err);
          appendMsg("Audio permission error: Please tap the screen to enable audio, or check browser settings.", "bot");
        });
      }
    }

    // Enable audio context and speech synthesis only for non-iOS users
    if (!isIOS) {
      window.addEventListener("click", () => {
        if (audioContext && audioContext.state === "suspended") {
          audioContext.resume().then(() => {
            console.log("Audio resumed after user click");
          });
        }
        if (speechSynthesis.paused) {
          speechSynthesis.resume();
          console.log("Speech synthesis resumed after user click");
        }
      });

      document.addEventListener("visibilitychange", () => {
        if (document.visibilityState === "visible") {
          console.log("App foregrounded, resuming audio context");
          initAudioContext();
          if (speechSynthesis.paused) {
            speechSynthesis.resume();
            console.log("Speech synthesis resumed on app foreground");
          }
        } else {
          console.log("App backgrounded, pausing speech synthesis");
          speechSynthesis.pause();
        }
      });

      speechSynthesis.onvoiceschanged = () => {
        voicesLoaded = true;
        console.log('Voices loaded:', speechSynthesis.getVoices().map(v => `${v.name} (${v.lang})`));
      };

      window.addEventListener('load', () => {
        initAudioContext();
        speechSynthesis.getVoices();
        setTimeout(() => {
          if (!voicesLoaded) {
            speechSynthesis.getVoices();
            console.log('Forced voice load after 200ms');
          }
        }, 200);
      });

      if ('speechSynthesis' in window) {
        console.log('SpeechSynthesis supported by browser');
      } else {
        console.error('SpeechSynthesis not supported by browser');
        appendMsg("Speech output is not supported by your browser. Please try a different browser.", "bot");
      }
    }

    function getFemaleBritishVoice() {
      const voices = speechSynthesis.getVoices();
      console.log('Available voices:', voices.map(v => `${v.name} (${v.lang})`));
      const femaleBritishVoice = voices.find(voice => 
        voice.lang === 'en-GB' && 
        (voice.name.includes('Female') || 
         voice.name.includes('Samantha') || 
         voice.name.includes('Kate') || 
         voice.name.includes('Serena')) && 
        !voice.name.includes('Male') && 
        !voice.name.includes('Daniel')
      ) || voices.find(voice => voice.lang === 'en-GB') || voices[0];
      if (femaleBritishVoice) {
        console.log('Selected voice:', femaleBritishVoice.name, femaleBritishVoice.lang);
      } else {
        console.warn('No suitable voice found, using first available voice');
      }
      return femaleBritishVoice;
    }

    function speakMessage(messageId) {
      if (isIOS) return; // Skip speech for iOS users

      console.log('speakMessage called with messageId:', messageId);
      initAudioContext();

      const msgEl = document.querySelector(`.msg[data-message-id="${messageId}"]`);
      if (!msgEl) {
        console.error("Couldn't find message with ID", messageId);
        appendMsg("Error: Could not find message to speak.", "bot");
        return;
      }

      const text = msgEl.dataset.messageContent?.trim();
      if (!text || text.length < 2) {
        console.warn("No message content found or too short to speak:", text);
        appendMsg("Error: Message content is empty or too short to speak.", "bot");
        return;
      }

      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-GB';
      utter.rate = 1.0;
      utter.pitch = 1.2;

      const voice = getFemaleBritishVoice();
      if (voice) utter.voice = voice;

      isSpeaking = true;
      if (recognition && isMicActive) {
        recognition.stop();
        console.log('SpeechRecognition paused during speech synthesis');
      }

      utter.onstart = () => {
        console.log('Speech synthesis started');
      };

      utter.onend = () => {
        console.log('Speech synthesis ended');
        isSpeaking = false;
        if (isMicActive && recognition && micErrorCount < MAX_MIC_ERRORS) {
          setTimeout(() => {
            recognition.start();
            console.log('SpeechRecognition resumed after speech synthesis with delay');
          }, RECOGNITION_RESTART_DELAY);
        }
      };

      utter.onerror = (e) => {
        console.error('Speech synthesis error:', e.error);
        appendMsg("Speech synthesis failed: " + e.error + ". Please check audio settings and browser permissions.", "bot");
        isSpeaking = false;
        if (isMicActive && recognition && micErrorCount < MAX_MIC_ERRORS) {
          setTimeout(() => {
            recognition.start();
            console.log('SpeechRecognition resumed after speech synthesis error with delay');
          }, RECOGNITION_RESTART_DELAY);
        }
      };

      speechSynthesis.cancel();
      speechSynthesis.speak(utter);
      console.log('Speech synthesis initiated for message:', text);
    }

    async function send(fromMic = false) {
      console.log('send() called');
      const text = input.value.trim();
      if (!text) {
        console.log('No text entered, exiting send()');
        return;
      }
      appendMsg(text, 'user');
      input.value = '';
      showThinkingAnimation();
      console.log('Starting wait timer at', new Date().toISOString());
      try {
        setTimeout(async () => {
          console.log('Wait timer ended at', new Date().toISOString());
          try {
            const res = await fetch("https://aichatbot-vx48.vercel.app/api/chat", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ messages: [{ role: "user", content: text }] })
            });
            const data = await res.json();
            removeThinkingAnimation();
            const reply = data.reply || "No response";
            const messageId = appendMsg(reply, "bot");
            if (fromMic && !isIOS) {
              console.log('Auto-speaking message after mic input:', messageId);
              speakMessage(messageId);
            }
          } catch (err) {
            console.error('Fetch error in send():', err);
            removeThinkingAnimation();
            appendMsg("Connection error. Ensure you're on HTTPS and check your network.", "bot");
          }
        }, 2000);
      } catch (err) {
        console.error('Error in send() setTimeout:', err);
        removeThinkingAnimation();
        appendMsg("Error sending message: " + err.message, "bot");
      }
    }

    sendBtn.addEventListener('click', () => {
      console.log('Send button clicked');
      send();
    });

    input.addEventListener("keypress", e => {
      if (e.key === "Enter") {
        console.log('Enter key pressed');
        send();
      }
    });

    // Enable mic button only for non-iOS users
    if (!isIOS) {
      micIcon.onclick = async () => {
        console.log('micIcon clicked');
        if (micErrorCount >= MAX_MIC_ERRORS) {
          appendMsg("Voice input disabled due to repeated errors. Please type your message instead.", "bot");
          micIcon.style.display = 'none';
          return;
        }
        if (!window.location.protocol.startsWith('https')) {
          appendMsg("Voice input requires HTTPS. Please access this site via a secure connection.", "bot");
          appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
          return;
        }

        if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {
          appendMsg("Voice input is not supported on this device.", "bot");
          return;
        }

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (micIcon.classList.contains('active')) {
          if (recognition) {
            recognition.stop();
            recognition = null;
            micIcon.classList.remove('active');
            isMicActive = false;
            console.log('Microphone stopped');
          }
          return;
        }

        recognition = new SpeechRecognition();
        recognition.lang = "en-GB";
        recognition.interimResults = true;
        recognition.maxAlternatives = 1;
        recognition.continuous = false;

        try {
          const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
          console.log('Microphone permission status:', permissionStatus.state);
          if (permissionStatus.state === 'denied') {
            appendMsg("Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone.", "bot");
            appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
            return;
          }

          await navigator.mediaDevices.getUserMedia({ audio: true });
          recognition.start();
          micIcon.classList.add('active');
          isMicActive = true;
          console.log('Microphone started successfully');
        } catch (err) {
          console.error('Microphone initialization error:', err);
          appendMsg("Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone. Error: " + err.message, "bot");
          appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
          return;
        }

        recognition.onresult = (e) => {
          const now = Date.now();
          if (now - lastSpeechTime < DEBOUNCE_DELAY || isSpeaking) {
            console.log('Debounced duplicate speech input or bot is speaking');
            return;
          }
          lastSpeechTime = now;
          const transcript = e.results[0][0].transcript;
          console.log('Speech recognition result:', transcript);
          input.value = transcript;
          send(true);
        };

        recognition.onerror = (e) => {
          micIcon.classList.remove('active');
          isMicActive = false;
          micErrorCount++;
          let errorMsg = "Voice input error: ";
          if (e.error === "no-speech") {
            errorMsg += "No speech detected. Please try again.";
          } else if (e.error === "audio-capture") {
            errorMsg += "No microphone detected. Please ensure a microphone is connected.";
          } else if (e.error === "not-allowed") {
            errorMsg += "Microphone access denied. Please enable permissions in your browser settings: Settings > Privacy > Microphone.";
          } else if (e.error === "network") {
            errorMsg += "Network error with speech recognition. Please check your internet connection, disable VPN if active, and ensure speech services are accessible.";
          } else {
            errorMsg += e.error;
          }
          console.error('Speech recognition error:', e.error);
          appendMsg(errorMsg, "bot");
          appendMsg("Alternatively, click <a href='https://aichatbot-vx48.vercel.app/chat.html' target='_blank'>here</a> to open in a new tab.", "bot");
          if (micErrorCount >= MAX_MIC_ERRORS) {
            appendMsg("Voice input disabled due to repeated errors. Please type your message instead.", "bot");
            micIcon.style.display = 'none';
          }
          recognition = null;
        };

        recognition.onend = () => {
          console.log('Speech recognition ended');
          if (micIcon.classList.contains('active') && micErrorCount < MAX_MIC_ERRORS && !isSpeaking) {
            setTimeout(() => {
              recognition.start();
              console.log('Speech recognition restarted with delay');
            }, RECOGNITION_RESTART_DELAY);
          }
        };
      };
    }
  </script>
</body>
</html>
